{"cells":[{"cell_type":"markdown","source":["# CNN evaluation for cifar10\n"],"metadata":{"id":"_caibiu5blWe"}},{"cell_type":"code","source":["#import adahessian\n","!pip install torch_optimizer\n","import torch_optimizer as ada_optim"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tgCrRqHGbrZO","executionInfo":{"status":"ok","timestamp":1717460319604,"user_tz":180,"elapsed":77969,"user":{"displayName":"Henrique Theodor Schutz Foerste","userId":"02049162976222168480"}},"outputId":"3b94fe55-7485-45f4-a46b-3d9ee0436c80"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting torch_optimizer\n","  Downloading torch_optimizer-0.3.0-py3-none-any.whl (61 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/61.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m51.2/61.9 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.9/61.9 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: torch>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from torch_optimizer) (2.3.0+cu121)\n","Collecting pytorch-ranger>=0.1.1 (from torch_optimizer)\n","  Downloading pytorch_ranger-0.1.1-py3-none-any.whl (14 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->torch_optimizer) (3.14.0)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->torch_optimizer) (4.12.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->torch_optimizer) (1.12.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->torch_optimizer) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->torch_optimizer) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->torch_optimizer) (2023.6.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.5.0->torch_optimizer)\n","  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.5.0->torch_optimizer)\n","  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.5.0->torch_optimizer)\n","  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.5.0->torch_optimizer)\n","  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.5.0->torch_optimizer)\n","  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.5.0->torch_optimizer)\n","  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.5.0->torch_optimizer)\n","  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.5.0->torch_optimizer)\n","  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.5.0->torch_optimizer)\n","  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.5.0->torch_optimizer)\n","  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n","Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.5.0->torch_optimizer)\n","  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->torch_optimizer) (2.3.0)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.5.0->torch_optimizer)\n","  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m49.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.5.0->torch_optimizer) (2.1.5)\n","Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.5.0->torch_optimizer) (1.3.0)\n","Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, pytorch-ranger, torch_optimizer\n","Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 pytorch-ranger-0.1.1 torch_optimizer-0.3.0\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9517,"status":"ok","timestamp":1717460337256,"user":{"displayName":"Henrique Theodor Schutz Foerste","userId":"02049162976222168480"},"user_tz":180},"id":"ACpEMzYL2vh-","outputId":"1907f6a3-4aa2-4fba-836d-4d6ace60050e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 170498071/170498071 [00:03<00:00, 47417205.88it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ./data/cifar-10-python.tar.gz to ./data\n","Files already downloaded and verified\n"]}],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision\n","import torchvision.transforms as transforms\n","import os\n","\n","# Device configuration\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","device\n","\n","# Carregar e Pré-processar o CIFAR-10\n","transform = transforms.Compose(\n","    [transforms.ToTensor(),\n","     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n","\n","trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n","                                        download=True, transform=transform)\n","trainloader = torch.utils.data.DataLoader(trainset, batch_size=64,\n","                                          shuffle=True, num_workers=2)\n","\n","testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n","                                       download=True, transform=transform)\n","testloader = torch.utils.data.DataLoader(testset, batch_size=64,\n","                                         shuffle=False, num_workers=2)\n","\n","# Definir o Modelo\n","class SimpleCNN(nn.Module):\n","    def __init__(self):\n","        super(SimpleCNN, self).__init__()\n","        self.conv1 = nn.Sequential(\n","            nn.Conv2d(3, 32, kernel_size=3, padding=1, bias=False),\n","            nn.ReLU()\n","        )\n","\n","        self.conv2 = nn.Sequential(\n","            nn.Conv2d(32, 64, kernel_size=3, padding=1, bias=False),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2),\n","            nn.Dropout(0.25)\n","        )\n","\n","        self.fc1 = nn.Sequential(\n","            nn.Linear(64 * 16 * 16, 128, bias=False),\n","            nn.ReLU(),\n","            nn.Dropout(0.5)\n","        )\n","\n","        self.out = nn.Linear(128, 10, bias=False)\n","\n","        self._initialize_weights()\n","\n","    def forward(self, x):\n","        x = self.conv1(x)\n","        x = self.conv2(x)\n","        x = x.view(x.size(0), -1)  # Flatten the output\n","        x = self.fc1(x)\n","        output = self.out(x)\n","        return output\n","\n","    def _initialize_weights(self):\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n","                nn.init.kaiming_normal_(m.weight)\n","            if isinstance(m, nn.Linear):\n","                nn.init.constant_(m.weight, 1e-4)  # Regularization term\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":604,"status":"ok","timestamp":1717460420612,"user":{"displayName":"Henrique Theodor Schutz Foerste","userId":"02049162976222168480"},"user_tz":180},"id":"D0mf5mhI2Wla","outputId":"86b53585-4eca-4468-ed37-4e6628ea2efa"},"outputs":[{"output_type":"stream","name":"stdout","text":["SimpleCNN(\n","  (conv1): Sequential(\n","    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (1): ReLU()\n","  )\n","  (conv2): Sequential(\n","    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (1): ReLU()\n","    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (3): Dropout(p=0.25, inplace=False)\n","  )\n","  (fc1): Sequential(\n","    (0): Linear(in_features=16384, out_features=128, bias=False)\n","    (1): ReLU()\n","    (2): Dropout(p=0.5, inplace=False)\n","  )\n","  (out): Linear(in_features=128, out_features=10, bias=False)\n",")\n"]}],"source":["# Instanciar o modelo\n","model = SimpleCNN().to(device)\n","print(model)\n","\n","# Definir a função de perda\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","# Treinar o modelo\n","def train(model, trainloader, testloader, criterion, optimizer, epochs=10):\n","    train_losses = []\n","    val_losses = []\n","\n","    for epoch in range(epochs):\n","        #training\n","        model.train()\n","        train_loss = 0.0\n","        for inputs, labels in trainloader:\n","            inputs, labels = inputs.to(device), labels.to(device)\n","\n","\n","            outputs = model(inputs)\n","            loss = criterion(outputs, labels)\n","\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","\n","\n","            train_loss += loss.item()*inputs.size(0)\n","        train_loss = train_loss/len(trainloader.dataset)\n","        train_losses.append(train_loss)\n","\n","        #validation\n","        model.eval()\n","        val_loss = 0.0\n","        correct = 0\n","        total = 0\n","        with torch.no_grad():\n","            for inputs, labels in testloader:\n","                inputs, labels = inputs.to(device), labels.to(device)\n","\n","                # Forward pass\n","                outputs = model(inputs)\n","                loss = criterion(outputs, labels)\n","\n","                val_loss += loss.item() * inputs.size(0)\n","\n","                # Calculate accuracy\n","                _, predicted = torch.max(outputs.data, 1)\n","                total += labels.size(0)\n","                correct += (predicted == labels).sum().item()\n","\n","        val_loss = val_loss / len(testloader.dataset)\n","        val_losses.append(val_loss)\n","        print('Epoch [{}/{}], Train Loss: {:.4f}, Val Loss: {:.4f}, Val Acc: {:.2f}%'\n","              .format(epoch+1, epochs, train_loss, val_loss, 100 * correct / total))\n","\n","\n","\n","\n","\n","    print(\"Finished Training/Validation\")\n","    return train_losses.copy(), val_losses.copy()\n","\n","#train(model, trainloader, testloader, criterion, optimizer, epochs=10)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3263,"status":"ok","timestamp":1717460430356,"user":{"displayName":"Henrique Theodor Schutz Foerste","userId":"02049162976222168480"},"user_tz":180},"id":"w1nGzkIM2eRa","outputId":"0224c81e-216a-4c14-a088-a4f94355dbe9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy of the network on the 10000 test images: 10.0 %\n","0.1\n"]}],"source":["# Avaliar o modelo\n","def test(model, testloader):\n","    model.eval()\n","    correct = 0\n","    total = 0\n","    with torch.no_grad():\n","        for inputs, labels in testloader:\n","            inputs, labels = inputs.to(device), labels.to(device)\n","            outputs = model(inputs)\n","            _, predicted = torch.max(outputs.data, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","    print(f'Accuracy of the network on the 10000 test images: {100 * correct / total} %')\n","    acc = correct/total\n","    return(acc)\n","\n","print(test(model, testloader))\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kk6nr0PW7xsW","executionInfo":{"status":"ok","timestamp":1717355370366,"user_tz":180,"elapsed":906109,"user":{"displayName":"Henrique Theodor Schutz Foerste","userId":"02049162976222168480"}},"outputId":"b2a40348-b2ca-4c2c-e22b-8eb26fb52750"},"outputs":[{"output_type":"stream","name":"stdout","text":["SimpleCNN(\n","  (conv1): Sequential(\n","    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (1): ReLU()\n","  )\n","  (conv2): Sequential(\n","    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (1): ReLU()\n","    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (3): Dropout(p=0.25, inplace=False)\n","  )\n","  (fc1): Sequential(\n","    (0): Linear(in_features=16384, out_features=128, bias=False)\n","    (1): ReLU()\n","    (2): Dropout(p=0.5, inplace=False)\n","  )\n","  (out): Linear(in_features=128, out_features=10, bias=False)\n",")\n","Epoch [1/50], Train Loss: 1.5902, Val Loss: 1.2271, Val Acc: 56.81%\n","Epoch [2/50], Train Loss: 1.2520, Val Loss: 1.0465, Val Acc: 63.11%\n","Epoch [3/50], Train Loss: 1.1086, Val Loss: 0.9864, Val Acc: 66.12%\n","Epoch [4/50], Train Loss: 1.0127, Val Loss: 0.9676, Val Acc: 66.24%\n","Epoch [5/50], Train Loss: 0.9359, Val Loss: 0.9148, Val Acc: 68.32%\n","Epoch [6/50], Train Loss: 0.8741, Val Loss: 0.8994, Val Acc: 69.16%\n","Epoch [7/50], Train Loss: 0.8110, Val Loss: 0.8975, Val Acc: 69.50%\n","Epoch [8/50], Train Loss: 0.7698, Val Loss: 0.8985, Val Acc: 69.75%\n","Epoch [9/50], Train Loss: 0.7366, Val Loss: 0.9013, Val Acc: 69.89%\n","Epoch [10/50], Train Loss: 0.6949, Val Loss: 0.9247, Val Acc: 70.05%\n","Epoch [11/50], Train Loss: 0.6649, Val Loss: 0.9161, Val Acc: 70.18%\n","Epoch [12/50], Train Loss: 0.6373, Val Loss: 0.9373, Val Acc: 69.59%\n","Epoch [13/50], Train Loss: 0.6051, Val Loss: 0.9458, Val Acc: 70.40%\n","Epoch [14/50], Train Loss: 0.5887, Val Loss: 0.9590, Val Acc: 70.46%\n","Epoch [15/50], Train Loss: 0.5792, Val Loss: 0.9475, Val Acc: 70.12%\n","Epoch [16/50], Train Loss: 0.5535, Val Loss: 0.9982, Val Acc: 70.51%\n","Epoch [17/50], Train Loss: 0.5390, Val Loss: 0.9849, Val Acc: 70.29%\n","Epoch [18/50], Train Loss: 0.5217, Val Loss: 1.0030, Val Acc: 70.06%\n","Epoch [19/50], Train Loss: 0.5074, Val Loss: 1.0111, Val Acc: 70.68%\n","Epoch [20/50], Train Loss: 0.4936, Val Loss: 1.0174, Val Acc: 70.54%\n","Epoch [21/50], Train Loss: 0.4879, Val Loss: 1.0555, Val Acc: 70.08%\n","Epoch [22/50], Train Loss: 0.4752, Val Loss: 1.0515, Val Acc: 70.33%\n","Epoch [23/50], Train Loss: 0.4720, Val Loss: 1.0575, Val Acc: 70.77%\n","Epoch [24/50], Train Loss: 0.4586, Val Loss: 1.0714, Val Acc: 70.77%\n","Epoch [25/50], Train Loss: 0.4520, Val Loss: 1.0620, Val Acc: 70.98%\n","Epoch [26/50], Train Loss: 0.4461, Val Loss: 1.0796, Val Acc: 70.61%\n","Epoch [27/50], Train Loss: 0.4411, Val Loss: 1.0517, Val Acc: 70.63%\n","Epoch [28/50], Train Loss: 0.4304, Val Loss: 1.1280, Val Acc: 70.28%\n","Epoch [29/50], Train Loss: 0.4291, Val Loss: 1.0957, Val Acc: 70.66%\n","Epoch [30/50], Train Loss: 0.4223, Val Loss: 1.1142, Val Acc: 70.88%\n","Epoch [31/50], Train Loss: 0.4136, Val Loss: 1.0961, Val Acc: 70.94%\n","Epoch [32/50], Train Loss: 0.4084, Val Loss: 1.1025, Val Acc: 70.92%\n","Epoch [33/50], Train Loss: 0.4035, Val Loss: 1.1257, Val Acc: 70.75%\n","Epoch [34/50], Train Loss: 0.4080, Val Loss: 1.1650, Val Acc: 70.56%\n","Epoch [35/50], Train Loss: 0.3955, Val Loss: 1.1350, Val Acc: 70.72%\n","Epoch [36/50], Train Loss: 0.3939, Val Loss: 1.1799, Val Acc: 70.85%\n","Epoch [37/50], Train Loss: 0.3892, Val Loss: 1.1559, Val Acc: 71.04%\n","Epoch [38/50], Train Loss: 0.3843, Val Loss: 1.1822, Val Acc: 70.33%\n","Epoch [39/50], Train Loss: 0.3776, Val Loss: 1.1605, Val Acc: 71.03%\n","Epoch [40/50], Train Loss: 0.3766, Val Loss: 1.2215, Val Acc: 70.98%\n","Epoch [41/50], Train Loss: 0.3776, Val Loss: 1.2024, Val Acc: 70.68%\n","Epoch [42/50], Train Loss: 0.3665, Val Loss: 1.1827, Val Acc: 70.95%\n","Epoch [43/50], Train Loss: 0.3629, Val Loss: 1.1832, Val Acc: 70.97%\n","Epoch [44/50], Train Loss: 0.3589, Val Loss: 1.1718, Val Acc: 70.59%\n","Epoch [45/50], Train Loss: 0.3612, Val Loss: 1.1805, Val Acc: 70.70%\n","Epoch [46/50], Train Loss: 0.3476, Val Loss: 1.2217, Val Acc: 70.74%\n","Epoch [47/50], Train Loss: 0.3566, Val Loss: 1.2111, Val Acc: 70.99%\n","Epoch [48/50], Train Loss: 0.3518, Val Loss: 1.2187, Val Acc: 70.49%\n","Epoch [49/50], Train Loss: 0.3445, Val Loss: 1.2200, Val Acc: 70.62%\n","Epoch [50/50], Train Loss: 0.3473, Val Loss: 1.2353, Val Acc: 71.18%\n","Finished Training/Validation\n","Accuracy of the network on the 10000 test images: 71.18 %\n"]}],"source":["results={}\n","\n","\n","#ADAM\n","# Instanciar o modelo\n","model = SimpleCNN().to(device)\n","print(model)\n","\n","# Definir a função de perda\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","\n","\n","\n","model_perform={}\n","\n","#treina o modelo com 50 epocas\n","model_perform['train_losses'], model_perform['validation_losses'] = train(model, trainloader, testloader, criterion, optimizer, epochs=50)\n","model_perform['accuracy'] = test(model, testloader)\n","results['adam'] = model_perform\n","torch.save(model.state_dict(),'adam_cnn_cifa10')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":907240,"status":"ok","timestamp":1717356318560,"user":{"displayName":"Henrique Theodor Schutz Foerste","userId":"02049162976222168480"},"user_tz":180},"id":"_LaVD2UPK1RX","outputId":"41844298-3ada-42c2-d7d7-1eb26f52ed48"},"outputs":[{"output_type":"stream","name":"stdout","text":["SimpleCNN(\n","  (conv1): Sequential(\n","    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (1): ReLU()\n","  )\n","  (conv2): Sequential(\n","    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (1): ReLU()\n","    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (3): Dropout(p=0.25, inplace=False)\n","  )\n","  (fc1): Sequential(\n","    (0): Linear(in_features=16384, out_features=128, bias=False)\n","    (1): ReLU()\n","    (2): Dropout(p=0.5, inplace=False)\n","  )\n","  (out): Linear(in_features=128, out_features=10, bias=False)\n",")\n","Epoch [1/50], Train Loss: 2.3001, Val Loss: 2.2985, Val Acc: 12.29%\n","Epoch [2/50], Train Loss: 2.2870, Val Loss: 2.2510, Val Acc: 15.89%\n","Epoch [3/50], Train Loss: 2.1694, Val Loss: 2.0897, Val Acc: 21.98%\n","Epoch [4/50], Train Loss: 2.0550, Val Loss: 1.9961, Val Acc: 26.85%\n","Epoch [5/50], Train Loss: 1.9803, Val Loss: 1.9258, Val Acc: 30.16%\n","Epoch [6/50], Train Loss: 1.9183, Val Loss: 1.8657, Val Acc: 32.69%\n","Epoch [7/50], Train Loss: 1.8670, Val Loss: 1.8136, Val Acc: 34.62%\n","Epoch [8/50], Train Loss: 1.8249, Val Loss: 1.7708, Val Acc: 36.43%\n","Epoch [9/50], Train Loss: 1.7849, Val Loss: 1.7276, Val Acc: 37.78%\n","Epoch [10/50], Train Loss: 1.7459, Val Loss: 1.6883, Val Acc: 39.51%\n","Epoch [11/50], Train Loss: 1.7100, Val Loss: 1.6498, Val Acc: 40.88%\n","Epoch [12/50], Train Loss: 1.6759, Val Loss: 1.6124, Val Acc: 42.24%\n","Epoch [13/50], Train Loss: 1.6452, Val Loss: 1.5864, Val Acc: 42.74%\n","Epoch [14/50], Train Loss: 1.6141, Val Loss: 1.5521, Val Acc: 44.44%\n","Epoch [15/50], Train Loss: 1.5907, Val Loss: 1.5268, Val Acc: 45.11%\n","Epoch [16/50], Train Loss: 1.5659, Val Loss: 1.4985, Val Acc: 46.13%\n","Epoch [17/50], Train Loss: 1.5431, Val Loss: 1.4760, Val Acc: 47.17%\n","Epoch [18/50], Train Loss: 1.5226, Val Loss: 1.4567, Val Acc: 47.81%\n","Epoch [19/50], Train Loss: 1.4989, Val Loss: 1.4380, Val Acc: 48.36%\n","Epoch [20/50], Train Loss: 1.4817, Val Loss: 1.4202, Val Acc: 49.31%\n","Epoch [21/50], Train Loss: 1.4619, Val Loss: 1.4127, Val Acc: 49.15%\n","Epoch [22/50], Train Loss: 1.4437, Val Loss: 1.3907, Val Acc: 50.18%\n","Epoch [23/50], Train Loss: 1.4286, Val Loss: 1.3715, Val Acc: 50.97%\n","Epoch [24/50], Train Loss: 1.4161, Val Loss: 1.3587, Val Acc: 51.64%\n","Epoch [25/50], Train Loss: 1.3982, Val Loss: 1.3459, Val Acc: 52.20%\n","Epoch [26/50], Train Loss: 1.3872, Val Loss: 1.3296, Val Acc: 53.02%\n","Epoch [27/50], Train Loss: 1.3760, Val Loss: 1.3197, Val Acc: 53.82%\n","Epoch [28/50], Train Loss: 1.3609, Val Loss: 1.3069, Val Acc: 53.77%\n","Epoch [29/50], Train Loss: 1.3469, Val Loss: 1.2974, Val Acc: 54.52%\n","Epoch [30/50], Train Loss: 1.3345, Val Loss: 1.2928, Val Acc: 54.32%\n","Epoch [31/50], Train Loss: 1.3232, Val Loss: 1.2789, Val Acc: 55.54%\n","Epoch [32/50], Train Loss: 1.3156, Val Loss: 1.2679, Val Acc: 55.81%\n","Epoch [33/50], Train Loss: 1.3029, Val Loss: 1.2664, Val Acc: 55.63%\n","Epoch [34/50], Train Loss: 1.2943, Val Loss: 1.2519, Val Acc: 55.59%\n","Epoch [35/50], Train Loss: 1.2805, Val Loss: 1.2446, Val Acc: 56.26%\n","Epoch [36/50], Train Loss: 1.2736, Val Loss: 1.2442, Val Acc: 55.68%\n","Epoch [37/50], Train Loss: 1.2648, Val Loss: 1.2279, Val Acc: 56.56%\n","Epoch [38/50], Train Loss: 1.2532, Val Loss: 1.2236, Val Acc: 56.81%\n","Epoch [39/50], Train Loss: 1.2416, Val Loss: 1.2122, Val Acc: 57.43%\n","Epoch [40/50], Train Loss: 1.2358, Val Loss: 1.2016, Val Acc: 57.51%\n","Epoch [41/50], Train Loss: 1.2261, Val Loss: 1.2074, Val Acc: 57.19%\n","Epoch [42/50], Train Loss: 1.2151, Val Loss: 1.1910, Val Acc: 57.72%\n","Epoch [43/50], Train Loss: 1.2073, Val Loss: 1.1892, Val Acc: 58.35%\n","Epoch [44/50], Train Loss: 1.1996, Val Loss: 1.1713, Val Acc: 58.61%\n","Epoch [45/50], Train Loss: 1.1915, Val Loss: 1.1683, Val Acc: 58.70%\n","Epoch [46/50], Train Loss: 1.1800, Val Loss: 1.1639, Val Acc: 59.06%\n","Epoch [47/50], Train Loss: 1.1736, Val Loss: 1.1573, Val Acc: 59.14%\n","Epoch [48/50], Train Loss: 1.1604, Val Loss: 1.1502, Val Acc: 59.67%\n","Epoch [49/50], Train Loss: 1.1536, Val Loss: 1.1445, Val Acc: 59.98%\n","Epoch [50/50], Train Loss: 1.1463, Val Loss: 1.1310, Val Acc: 60.37%\n","Finished Training/Validation\n","Accuracy of the network on the 10000 test images: 60.37 %\n"]}],"source":["#SGD\n","\n","# Instanciar o modelo\n","model = SimpleCNN().to(device)\n","print(model)\n","\n","# Definir a função de perda\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(model.parameters(), lr=0.001)\n","\n","\n","\n","model_perform={}\n","#treina o modelo com 30 epocas\n","model_perform['train_losses'], model_perform['validation_losses'] = train(model, trainloader, testloader, criterion, optimizer, epochs=50)\n","model_perform['accuracy'] = test(model, testloader)\n","results['sgd'] = model_perform\n","torch.save(model.state_dict(),'sgd_cnn_cifar10')"]},{"cell_type":"code","source":["# Treinar o modelo\n","def train_hess(model, trainloader, testloader, criterion, optimizer, epochs=10):\n","    train_losses = []\n","    val_losses = []\n","\n","    for epoch in range(epochs):\n","        #training\n","        model.train()\n","        train_loss = 0.0\n","        for inputs, labels in trainloader:\n","            inputs, labels = inputs.to(device), labels.to(device)\n","\n","\n","            outputs = model(inputs)\n","            loss = criterion(outputs, labels)\n","\n","            optimizer.zero_grad()\n","            loss.backward(create_graph=True)\n","            optimizer.step()\n","\n","\n","            train_loss += loss.item()*inputs.size(0)\n","        train_loss = train_loss/len(trainloader.dataset)\n","        train_losses.append(train_loss)\n","\n","        #validation\n","        model.eval()\n","        val_loss = 0.0\n","        correct = 0\n","        total = 0\n","        with torch.no_grad():\n","            for inputs, labels in testloader:\n","                inputs, labels = inputs.to(device), labels.to(device)\n","\n","                # Forward pass\n","                outputs = model(inputs)\n","                loss = criterion(outputs, labels)\n","\n","                val_loss += loss.item() * inputs.size(0)\n","\n","                # Calculate accuracy\n","                _, predicted = torch.max(outputs.data, 1)\n","                total += labels.size(0)\n","                correct += (predicted == labels).sum().item()\n","\n","        val_loss = val_loss / len(testloader.dataset)\n","        val_losses.append(val_loss)\n","        print('Epoch [{}/{}], Train Loss: {:.4f}, Val Loss: {:.4f}, Val Acc: {:.2f}%'\n","              .format(epoch+1, epochs, train_loss, val_loss, 100 * correct / total))\n","\n","\n","\n","\n","\n","    print(\"Finished Training/Validation\")\n","    return train_losses.copy(), val_losses.copy()\n","\n","\n","#ADAHESSIAN\n","\n","# Instanciar o modelo\n","model = SimpleCNN().to(device)\n","print(model)\n","\n","# Definir a função de perda\n","criterion = nn.CrossEntropyLoss()\n","optimizer = ada_optim.Adahessian(model.parameters(), lr = 0.001)\n","\n","\n","\n","model_perform={}\n","#treina o modelo com 30 epocas\n","model_perform['train_losses'], model_perform['validation_losses'] = train_hess(model, trainloader, testloader, criterion, optimizer, epochs=50)\n","model_perform['accuracy'] = test(model, testloader)\n","results['Adahessian'] = model_perform\n","torch.save(model.state_dict(),'adahessian_cnn_cifar10')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RNZejq2ibSGm","executionInfo":{"status":"ok","timestamp":1717358285890,"user_tz":180,"elapsed":1120776,"user":{"displayName":"Henrique Theodor Schutz Foerste","userId":"02049162976222168480"}},"outputId":"3eb53920-3bfa-413f-c40e-f25bdd72425b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["SimpleCNN(\n","  (conv1): Sequential(\n","    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (1): ReLU()\n","  )\n","  (conv2): Sequential(\n","    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (1): ReLU()\n","    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (3): Dropout(p=0.25, inplace=False)\n","  )\n","  (fc1): Sequential(\n","    (0): Linear(in_features=16384, out_features=128, bias=False)\n","    (1): ReLU()\n","    (2): Dropout(p=0.5, inplace=False)\n","  )\n","  (out): Linear(in_features=128, out_features=10, bias=False)\n",")\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:744: UserWarning: Using backward() with create_graph=True will create a reference cycle between the parameter and its gradient which can cause a memory leak. We recommend using autograd.grad when creating the graph to avoid this. If you have to use this function, make sure to reset the .grad fields of your parameters to None after use to break the cycle and avoid the leak. (Triggered internally at ../torch/csrc/autograd/engine.cpp:1203.)\n","  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n","/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:744: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n","  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [1/50], Train Loss: 2.3003, Val Loss: 2.2981, Val Acc: 10.00%\n","Epoch [2/50], Train Loss: 2.2901, Val Loss: 2.2673, Val Acc: 15.79%\n","Epoch [3/50], Train Loss: 2.1889, Val Loss: 2.0961, Val Acc: 20.89%\n","Epoch [4/50], Train Loss: 2.0516, Val Loss: 1.9843, Val Acc: 26.24%\n","Epoch [5/50], Train Loss: 1.9670, Val Loss: 1.9058, Val Acc: 31.75%\n","Epoch [6/50], Train Loss: 1.9025, Val Loss: 1.8402, Val Acc: 34.61%\n","Epoch [7/50], Train Loss: 1.8449, Val Loss: 1.7798, Val Acc: 36.58%\n","Epoch [8/50], Train Loss: 1.7925, Val Loss: 1.7251, Val Acc: 38.61%\n","Epoch [9/50], Train Loss: 1.7433, Val Loss: 1.6740, Val Acc: 40.11%\n","Epoch [10/50], Train Loss: 1.6972, Val Loss: 1.6275, Val Acc: 41.68%\n","Epoch [11/50], Train Loss: 1.6578, Val Loss: 1.5875, Val Acc: 42.97%\n","Epoch [12/50], Train Loss: 1.6197, Val Loss: 1.5555, Val Acc: 44.40%\n","Epoch [13/50], Train Loss: 1.5902, Val Loss: 1.5254, Val Acc: 45.29%\n","Epoch [14/50], Train Loss: 1.5609, Val Loss: 1.4962, Val Acc: 46.00%\n","Epoch [15/50], Train Loss: 1.5355, Val Loss: 1.4671, Val Acc: 47.14%\n","Epoch [16/50], Train Loss: 1.5118, Val Loss: 1.4481, Val Acc: 48.11%\n","Epoch [17/50], Train Loss: 1.4924, Val Loss: 1.4265, Val Acc: 48.74%\n","Epoch [18/50], Train Loss: 1.4670, Val Loss: 1.4097, Val Acc: 49.61%\n","Epoch [19/50], Train Loss: 1.4500, Val Loss: 1.3926, Val Acc: 50.15%\n","Epoch [20/50], Train Loss: 1.4356, Val Loss: 1.3794, Val Acc: 50.84%\n","Epoch [21/50], Train Loss: 1.4208, Val Loss: 1.3646, Val Acc: 51.20%\n","Epoch [22/50], Train Loss: 1.4048, Val Loss: 1.3454, Val Acc: 52.09%\n","Epoch [23/50], Train Loss: 1.3890, Val Loss: 1.3357, Val Acc: 52.48%\n","Epoch [24/50], Train Loss: 1.3759, Val Loss: 1.3284, Val Acc: 53.02%\n","Epoch [25/50], Train Loss: 1.3678, Val Loss: 1.3149, Val Acc: 53.30%\n","Epoch [26/50], Train Loss: 1.3529, Val Loss: 1.3062, Val Acc: 53.73%\n","Epoch [27/50], Train Loss: 1.3393, Val Loss: 1.2946, Val Acc: 54.31%\n","Epoch [28/50], Train Loss: 1.3268, Val Loss: 1.2862, Val Acc: 54.68%\n","Epoch [29/50], Train Loss: 1.3163, Val Loss: 1.2778, Val Acc: 54.96%\n","Epoch [30/50], Train Loss: 1.3079, Val Loss: 1.2641, Val Acc: 55.52%\n","Epoch [31/50], Train Loss: 1.2993, Val Loss: 1.2572, Val Acc: 55.70%\n","Epoch [32/50], Train Loss: 1.2867, Val Loss: 1.2514, Val Acc: 55.67%\n","Epoch [33/50], Train Loss: 1.2806, Val Loss: 1.2435, Val Acc: 55.79%\n","Epoch [34/50], Train Loss: 1.2667, Val Loss: 1.2338, Val Acc: 56.69%\n","Epoch [35/50], Train Loss: 1.2602, Val Loss: 1.2250, Val Acc: 56.58%\n","Epoch [36/50], Train Loss: 1.2492, Val Loss: 1.2222, Val Acc: 57.03%\n","Epoch [37/50], Train Loss: 1.2403, Val Loss: 1.2113, Val Acc: 57.16%\n","Epoch [38/50], Train Loss: 1.2329, Val Loss: 1.2058, Val Acc: 57.31%\n","Epoch [39/50], Train Loss: 1.2235, Val Loss: 1.2035, Val Acc: 57.33%\n","Epoch [40/50], Train Loss: 1.2160, Val Loss: 1.1936, Val Acc: 58.34%\n","Epoch [41/50], Train Loss: 1.2059, Val Loss: 1.1855, Val Acc: 58.01%\n","Epoch [42/50], Train Loss: 1.2000, Val Loss: 1.1796, Val Acc: 58.27%\n","Epoch [43/50], Train Loss: 1.1885, Val Loss: 1.1740, Val Acc: 58.83%\n","Epoch [44/50], Train Loss: 1.1838, Val Loss: 1.1676, Val Acc: 58.43%\n","Epoch [45/50], Train Loss: 1.1782, Val Loss: 1.1614, Val Acc: 58.91%\n","Epoch [46/50], Train Loss: 1.1665, Val Loss: 1.1542, Val Acc: 59.70%\n","Epoch [47/50], Train Loss: 1.1633, Val Loss: 1.1465, Val Acc: 59.63%\n","Epoch [48/50], Train Loss: 1.1525, Val Loss: 1.1434, Val Acc: 60.18%\n","Epoch [49/50], Train Loss: 1.1457, Val Loss: 1.1390, Val Acc: 59.98%\n","Epoch [50/50], Train Loss: 1.1412, Val Loss: 1.1380, Val Acc: 59.75%\n","Finished Training/Validation\n","Accuracy of the network on the 10000 test images: 59.75 %\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1717358453306,"user":{"displayName":"Henrique Theodor Schutz Foerste","userId":"02049162976222168480"},"user_tz":180},"id":"Jn19yeC-L-TO","outputId":"5cc7fe73-c2bc-4e57-bc06-f56e474e9632"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'adam': {'train_losses': [1.590164584465027,\n","   1.2519942048645019,\n","   1.1086417794799805,\n","   1.0127390199279784,\n","   0.9358503803253174,\n","   0.874054369392395,\n","   0.8110197282791137,\n","   0.7698344395637512,\n","   0.7366180632781982,\n","   0.6949183436584473,\n","   0.6649042266654969,\n","   0.6373139685630799,\n","   0.605095704870224,\n","   0.5887161101341247,\n","   0.579220671710968,\n","   0.5535266841793061,\n","   0.5390034580230713,\n","   0.5216813322257996,\n","   0.5074019215869904,\n","   0.4936124308204651,\n","   0.4878903732442856,\n","   0.4752003056716919,\n","   0.4720305403518677,\n","   0.4585906790828705,\n","   0.45204107931137083,\n","   0.4461482344055176,\n","   0.441104617767334,\n","   0.4303910920333862,\n","   0.42905445552825927,\n","   0.4222751952934265,\n","   0.41356560861587527,\n","   0.4084376046562195,\n","   0.40346481088638303,\n","   0.4079769277381897,\n","   0.3955028570461273,\n","   0.3938916843032837,\n","   0.38916474439620974,\n","   0.3842560176563263,\n","   0.377643616733551,\n","   0.37661827850341795,\n","   0.37761816915512086,\n","   0.36651902200222014,\n","   0.362888324174881,\n","   0.35888387969970703,\n","   0.36117295870780947,\n","   0.34755015257716176,\n","   0.35658752440452574,\n","   0.35180156658172607,\n","   0.3445219389629364,\n","   0.347333965511322],\n","  'validation_losses': [1.227099472618103,\n","   1.046548403930664,\n","   0.9863689215660095,\n","   0.9676219882011413,\n","   0.9147918231964112,\n","   0.8994213315963745,\n","   0.8974945436477662,\n","   0.8985006801605224,\n","   0.9013138993263244,\n","   0.9246547576904297,\n","   0.9160942157745361,\n","   0.9372734529495239,\n","   0.9458094563484192,\n","   0.9590299390792847,\n","   0.9475139017105103,\n","   0.9981917413711547,\n","   0.9848899782180787,\n","   1.0030361734390258,\n","   1.0111342485427857,\n","   1.0173753704071045,\n","   1.0555309000015258,\n","   1.0515123723983764,\n","   1.057529187297821,\n","   1.0713635703086852,\n","   1.0619718173980712,\n","   1.0795713928222657,\n","   1.0517119848251342,\n","   1.1280404106140136,\n","   1.0957063459396363,\n","   1.1141604035377501,\n","   1.0960929152488708,\n","   1.1024824989318847,\n","   1.125656040763855,\n","   1.165009277534485,\n","   1.1349609920501709,\n","   1.1798676935195922,\n","   1.155896432495117,\n","   1.1822431922912597,\n","   1.160453106880188,\n","   1.2214729787826537,\n","   1.20244501953125,\n","   1.182720745277405,\n","   1.1831819469451905,\n","   1.1718389612197877,\n","   1.1804557359695436,\n","   1.2217176908493041,\n","   1.2111256501197816,\n","   1.2186912669181824,\n","   1.2199837715148927,\n","   1.2353064406394958],\n","  'accuracy': 0.7118},\n"," 'sgd': {'train_losses': [2.300112315826416,\n","   2.287028645095825,\n","   2.1693725386047364,\n","   2.0549666287231445,\n","   1.9803386457061767,\n","   1.9183007612609864,\n","   1.8669505683898926,\n","   1.824855620689392,\n","   1.7848964277648927,\n","   1.7459018146514893,\n","   1.7100326007461548,\n","   1.6759333223724364,\n","   1.6451503852844238,\n","   1.6140886610412597,\n","   1.59071629901886,\n","   1.5659311952209474,\n","   1.5430639961242676,\n","   1.5225665803146362,\n","   1.4988531211853027,\n","   1.481671733856201,\n","   1.46186568775177,\n","   1.4437493642425536,\n","   1.4286047667312622,\n","   1.41610542137146,\n","   1.398249234085083,\n","   1.3872130709075927,\n","   1.3760212105178833,\n","   1.3609212716674806,\n","   1.3469104176712037,\n","   1.3345414585876465,\n","   1.3232211966323852,\n","   1.3156102284240723,\n","   1.3028838509368896,\n","   1.2943405065727234,\n","   1.2804504856491088,\n","   1.2735601488876342,\n","   1.264847137336731,\n","   1.2531841342926024,\n","   1.241560542755127,\n","   1.2357665762710572,\n","   1.226130982208252,\n","   1.215082363319397,\n","   1.2072790614700317,\n","   1.1996310301208497,\n","   1.191494501914978,\n","   1.180049096469879,\n","   1.173617470779419,\n","   1.1604349911499023,\n","   1.1536044628143312,\n","   1.1462542750549316],\n","  'validation_losses': [2.29847631149292,\n","   2.251006341934204,\n","   2.0897078031539915,\n","   1.9960591348648071,\n","   1.9258005451202393,\n","   1.8657427843093872,\n","   1.813598589515686,\n","   1.7708096385955812,\n","   1.7276498233795166,\n","   1.688256097793579,\n","   1.649776728439331,\n","   1.6124353481292724,\n","   1.586416738319397,\n","   1.5521224773406983,\n","   1.5268417318344116,\n","   1.4985439378738403,\n","   1.4759899696350098,\n","   1.456707022857666,\n","   1.4379584686279296,\n","   1.4201522214889526,\n","   1.4127104598999023,\n","   1.3907027032852173,\n","   1.371453876876831,\n","   1.3587031358718873,\n","   1.3458926235198974,\n","   1.3295693994522095,\n","   1.319709196472168,\n","   1.3069010612487792,\n","   1.2973677116394042,\n","   1.2927793329238892,\n","   1.2788761455535889,\n","   1.2678990224838256,\n","   1.2663519254684448,\n","   1.2519177434921265,\n","   1.2445528856277466,\n","   1.244184276008606,\n","   1.2279290412902832,\n","   1.2235683195114135,\n","   1.2122313336372375,\n","   1.2015718313217163,\n","   1.2074287322044372,\n","   1.1909618771553039,\n","   1.189159972000122,\n","   1.1713412457466126,\n","   1.168328870677948,\n","   1.1639262349128723,\n","   1.1572616581916808,\n","   1.1501674314498902,\n","   1.1445322150230408,\n","   1.131002944946289],\n","  'accuracy': 0.6037},\n"," 'Adahessian': {'train_losses': [2.300267517852783,\n","   2.2901430268096923,\n","   2.188936166534424,\n","   2.0515802210998535,\n","   1.9670093835830689,\n","   1.9025015752792358,\n","   1.8449413418579101,\n","   1.7924989828491211,\n","   1.743339294052124,\n","   1.6971755513763427,\n","   1.6578333689117433,\n","   1.619663718109131,\n","   1.5902247226715087,\n","   1.5609484342193602,\n","   1.535524635734558,\n","   1.5118297251129151,\n","   1.492388031578064,\n","   1.4669682010269165,\n","   1.450033404045105,\n","   1.4355797248458861,\n","   1.4208147137451173,\n","   1.4047708878326417,\n","   1.3890334538269042,\n","   1.3759057288742065,\n","   1.367834640235901,\n","   1.3529050099945068,\n","   1.3392588707733155,\n","   1.326843090057373,\n","   1.3162619505691528,\n","   1.3079352531051636,\n","   1.2992861337280273,\n","   1.2867393689727784,\n","   1.2806072607421874,\n","   1.2667420092391968,\n","   1.2601730399703979,\n","   1.2491527196884156,\n","   1.2403311031723023,\n","   1.2329197974586488,\n","   1.223481057472229,\n","   1.2160291701126098,\n","   1.2059074445343017,\n","   1.2000035441589356,\n","   1.1885259299850464,\n","   1.1837628115463257,\n","   1.178230959224701,\n","   1.1665135195541383,\n","   1.1632775369262696,\n","   1.1524911684036254,\n","   1.145690873336792,\n","   1.1411736603736877],\n","  'validation_losses': [2.298073947906494,\n","   2.2673465732574463,\n","   2.096058676338196,\n","   1.9843070249557495,\n","   1.9058438570022582,\n","   1.8401756494522095,\n","   1.779812666130066,\n","   1.7250706546783448,\n","   1.6740129011154175,\n","   1.6274644578933717,\n","   1.5874844272613526,\n","   1.5555357265472411,\n","   1.5253797798156739,\n","   1.496161359024048,\n","   1.4671256172180176,\n","   1.4480896780014039,\n","   1.4265436275482177,\n","   1.4097286911010742,\n","   1.3925811359405518,\n","   1.3794375806808472,\n","   1.3645821367263793,\n","   1.3454200582504272,\n","   1.3357095083236694,\n","   1.3283641033172608,\n","   1.3148846437454225,\n","   1.306212505531311,\n","   1.2946447692871095,\n","   1.2862070526123046,\n","   1.2778018928527832,\n","   1.2641109489440918,\n","   1.2571891771316528,\n","   1.2514229200363158,\n","   1.2435430479049683,\n","   1.2337593896865844,\n","   1.22503998336792,\n","   1.2221579315185547,\n","   1.2112533910751342,\n","   1.2058019584655761,\n","   1.2035234855651855,\n","   1.193552389717102,\n","   1.1855140602111816,\n","   1.1795900499343872,\n","   1.174017657470703,\n","   1.1675673795700072,\n","   1.161424868106842,\n","   1.1541846549987793,\n","   1.146480128288269,\n","   1.1434023270606994,\n","   1.1389746168136596,\n","   1.137963313293457],\n","  'accuracy': 0.5975}}"]},"metadata":{},"execution_count":21}],"source":["import json\n","with open('results.json', 'w') as f:\n","    json.dump(results, f)\n","results"]},{"cell_type":"markdown","source":["# MLP evaluation for cifar10"],"metadata":{"id":"fpTiBQX-j-vF"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision\n","import torchvision.transforms as transforms\n","import os\n","\n","# Device configuration\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","device\n","\n","# Carregar e Pré-processar o CIFAR-10\n","transform = transforms.Compose(\n","    [transforms.ToTensor(),\n","     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n","\n","trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n","                                        download=True, transform=transform)\n","trainloader = torch.utils.data.DataLoader(trainset, batch_size=64,\n","                                          shuffle=True, num_workers=2)\n","\n","testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n","                                       download=True, transform=transform)\n","testloader = torch.utils.data.DataLoader(testset, batch_size=64,\n","                                         shuffle=False, num_workers=2)\n","\n","# Definir o Modelo\n","\n","class SimpleMLP(nn.Module):\n","    def __init__(self, input_size=3*32*32, num_classes=10):\n","        super(SimpleMLP, self).__init__()\n","        self.fc1 = nn.Sequential(\n","            nn.Linear(input_size, 512, bias=False),\n","            nn.ReLU(),\n","            nn.Dropout(0.25)\n","        )\n","\n","        self.fc2 = nn.Sequential(\n","            nn.Linear(512, 256, bias=False),\n","            nn.ReLU(),\n","            nn.Dropout(0.5)\n","        )\n","\n","        self.out = nn.Linear(256, num_classes, bias=False)\n","\n","        self._initialize_weights()\n","\n","    def forward(self, x):\n","        x = x.view(x.size(0), -1)  # Flatten the input\n","        x = self.fc1(x)\n","        x = self.fc2(x)\n","        output = self.out(x)\n","        return output\n","\n","    def _initialize_weights(self):\n","        for m in self.modules():\n","            if isinstance(m, nn.Linear):\n","                nn.init.kaiming_normal_(m.weight)\n","                nn.init.constant_(m.weight, 1e-4)  # Regularization term\n","\n","# Treinar o modelo\n","def train(model, trainloader, testloader, criterion, optimizer, epochs=10):\n","    train_losses = []\n","    val_losses = []\n","\n","    for epoch in range(epochs):\n","        #training\n","        model.train()\n","        train_loss = 0.0\n","        for inputs, labels in trainloader:\n","            inputs, labels = inputs.to(device), labels.to(device)\n","\n","\n","            outputs = model(inputs)\n","            loss = criterion(outputs, labels)\n","\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","\n","\n","            train_loss += loss.item()*inputs.size(0)\n","        train_loss = train_loss/len(trainloader.dataset)\n","        train_losses.append(train_loss)\n","\n","        #validation\n","        model.eval()\n","        val_loss = 0.0\n","        correct = 0\n","        total = 0\n","        with torch.no_grad():\n","            for inputs, labels in testloader:\n","                inputs, labels = inputs.to(device), labels.to(device)\n","\n","                # Forward pass\n","                outputs = model(inputs)\n","                loss = criterion(outputs, labels)\n","\n","                val_loss += loss.item() * inputs.size(0)\n","\n","                # Calculate accuracy\n","                _, predicted = torch.max(outputs.data, 1)\n","                total += labels.size(0)\n","                correct += (predicted == labels).sum().item()\n","\n","        val_loss = val_loss / len(testloader.dataset)\n","        val_losses.append(val_loss)\n","        print('Epoch [{}/{}], Train Loss: {:.4f}, Val Loss: {:.4f}, Val Acc: {:.2f}%'\n","              .format(epoch+1, epochs, train_loss, val_loss, 100 * correct / total))\n","\n","\n","\n","\n","\n","    print(\"Finished Training/Validation\")\n","    return train_losses.copy(), val_losses.copy()\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7xUBVxGBkCx0","executionInfo":{"status":"ok","timestamp":1717462738351,"user_tz":180,"elapsed":23397,"user":{"displayName":"Henrique Theodor Schutz Foerste","userId":"02049162976222168480"}},"outputId":"423a80db-1fa2-48c6-d14a-fd92c03fb358"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 170498071/170498071 [00:03<00:00, 48553287.82it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ./data/cifar-10-python.tar.gz to ./data\n","Files already downloaded and verified\n"]}]},{"cell_type":"code","source":["results_mlp={}\n","\n","\n","#ADAM\n","# Instanciar o modelo\n","model = SimpleMLP().to(device)\n","print(model)\n","\n","# Definir a função de perda\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","\n","\n","\n","model_perform={}\n","\n","#treina o modelo com 30 epocas\n","model_perform['train_losses'], model_perform['validation_losses'] = train(model, trainloader, testloader, criterion, optimizer, epochs=50)\n","model_perform['accuracy'] = test(model, testloader)\n","results_mlp['adam'] = model_perform\n","torch.save(model.state_dict(),'adam_mlp_cifar10')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"2CqZuGCUkel6","executionInfo":{"status":"error","timestamp":1717464281899,"user_tz":180,"elapsed":1543561,"user":{"displayName":"Henrique Theodor Schutz Foerste","userId":"02049162976222168480"}},"outputId":"a464b166-23cb-4055-bdcf-2abeba0e868b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["SimpleMLP(\n","  (fc1): Sequential(\n","    (0): Linear(in_features=3072, out_features=512, bias=False)\n","    (1): ReLU()\n","    (2): Dropout(p=0.25, inplace=False)\n","  )\n","  (fc2): Sequential(\n","    (0): Linear(in_features=512, out_features=256, bias=False)\n","    (1): ReLU()\n","    (2): Dropout(p=0.5, inplace=False)\n","  )\n","  (out): Linear(in_features=256, out_features=10, bias=False)\n",")\n","Epoch [1/50], Train Loss: 1.8298, Val Loss: 1.5908, Val Acc: 43.00%\n","Epoch [2/50], Train Loss: 1.6631, Val Loss: 1.5325, Val Acc: 45.51%\n","Epoch [3/50], Train Loss: 1.6046, Val Loss: 1.4764, Val Acc: 48.36%\n","Epoch [4/50], Train Loss: 1.5674, Val Loss: 1.4703, Val Acc: 47.78%\n","Epoch [5/50], Train Loss: 1.5311, Val Loss: 1.4589, Val Acc: 48.42%\n","Epoch [6/50], Train Loss: 1.5053, Val Loss: 1.4299, Val Acc: 49.81%\n","Epoch [7/50], Train Loss: 1.4745, Val Loss: 1.4553, Val Acc: 49.53%\n","Epoch [8/50], Train Loss: 1.4552, Val Loss: 1.4105, Val Acc: 50.88%\n","Epoch [9/50], Train Loss: 1.4316, Val Loss: 1.4173, Val Acc: 51.40%\n","Epoch [10/50], Train Loss: 1.4199, Val Loss: 1.4161, Val Acc: 50.69%\n","Epoch [11/50], Train Loss: 1.3987, Val Loss: 1.4047, Val Acc: 51.06%\n","Epoch [12/50], Train Loss: 1.3782, Val Loss: 1.3929, Val Acc: 51.32%\n","Epoch [13/50], Train Loss: 1.3678, Val Loss: 1.4034, Val Acc: 51.66%\n","Epoch [14/50], Train Loss: 1.3498, Val Loss: 1.3944, Val Acc: 52.21%\n","Epoch [15/50], Train Loss: 1.3348, Val Loss: 1.4072, Val Acc: 51.35%\n","Epoch [16/50], Train Loss: 1.3169, Val Loss: 1.4319, Val Acc: 51.58%\n","Epoch [17/50], Train Loss: 1.3053, Val Loss: 1.3948, Val Acc: 51.77%\n","Epoch [18/50], Train Loss: 1.2989, Val Loss: 1.4140, Val Acc: 51.67%\n","Epoch [19/50], Train Loss: 1.2778, Val Loss: 1.4008, Val Acc: 52.04%\n","Epoch [20/50], Train Loss: 1.2751, Val Loss: 1.3978, Val Acc: 52.57%\n","Epoch [21/50], Train Loss: 1.2694, Val Loss: 1.4182, Val Acc: 51.94%\n","Epoch [22/50], Train Loss: 1.2460, Val Loss: 1.3972, Val Acc: 52.31%\n","Epoch [23/50], Train Loss: 1.2342, Val Loss: 1.3976, Val Acc: 52.70%\n","Epoch [24/50], Train Loss: 1.2289, Val Loss: 1.4211, Val Acc: 51.57%\n","Epoch [25/50], Train Loss: 1.2193, Val Loss: 1.4129, Val Acc: 52.32%\n","Epoch [26/50], Train Loss: 1.2182, Val Loss: 1.4155, Val Acc: 52.24%\n","Epoch [27/50], Train Loss: 1.2047, Val Loss: 1.4027, Val Acc: 52.50%\n","Epoch [28/50], Train Loss: 1.1891, Val Loss: 1.4199, Val Acc: 52.67%\n","Epoch [29/50], Train Loss: 1.1814, Val Loss: 1.4324, Val Acc: 51.95%\n","Epoch [30/50], Train Loss: 1.1705, Val Loss: 1.4193, Val Acc: 53.08%\n","Epoch [31/50], Train Loss: 1.1574, Val Loss: 1.4283, Val Acc: 52.04%\n","Epoch [32/50], Train Loss: 1.1505, Val Loss: 1.4217, Val Acc: 52.39%\n","Epoch [33/50], Train Loss: 1.1477, Val Loss: 1.4386, Val Acc: 52.57%\n","Epoch [34/50], Train Loss: 1.1415, Val Loss: 1.4411, Val Acc: 52.18%\n","Epoch [35/50], Train Loss: 1.1279, Val Loss: 1.4335, Val Acc: 51.71%\n","Epoch [36/50], Train Loss: 1.1175, Val Loss: 1.4295, Val Acc: 53.45%\n","Epoch [37/50], Train Loss: 1.1137, Val Loss: 1.4365, Val Acc: 52.21%\n","Epoch [38/50], Train Loss: 1.1142, Val Loss: 1.4465, Val Acc: 52.20%\n","Epoch [39/50], Train Loss: 1.1029, Val Loss: 1.4515, Val Acc: 51.86%\n","Epoch [40/50], Train Loss: 1.0933, Val Loss: 1.4663, Val Acc: 51.63%\n","Epoch [41/50], Train Loss: 1.0885, Val Loss: 1.4658, Val Acc: 52.69%\n","Epoch [42/50], Train Loss: 1.0794, Val Loss: 1.4694, Val Acc: 52.32%\n","Epoch [43/50], Train Loss: 1.0750, Val Loss: 1.4556, Val Acc: 52.46%\n","Epoch [44/50], Train Loss: 1.0720, Val Loss: 1.4618, Val Acc: 51.81%\n","Epoch [45/50], Train Loss: 1.0621, Val Loss: 1.4775, Val Acc: 52.61%\n","Epoch [46/50], Train Loss: 1.0571, Val Loss: 1.4863, Val Acc: 53.01%\n","Epoch [47/50], Train Loss: 1.0577, Val Loss: 1.4786, Val Acc: 52.21%\n","Epoch [48/50], Train Loss: 1.0550, Val Loss: 1.4882, Val Acc: 52.79%\n","Epoch [49/50], Train Loss: 1.0423, Val Loss: 1.4649, Val Acc: 52.96%\n","Epoch [50/50], Train Loss: 1.0315, Val Loss: 1.4895, Val Acc: 52.87%\n","Finished Training/Validation\n"]},{"output_type":"error","ename":"NameError","evalue":"name 'test' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-a58de76f1990>\u001b[0m in \u001b[0;36m<cell line: 20>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m#treina o modelo com 30 epocas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mmodel_perform\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train_losses'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_perform\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'validation_losses'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mmodel_perform\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0mresults_mlp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_perform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'adam_mlp_cifar10'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'test' is not defined"]}]},{"cell_type":"code","source":["#SGD\n","\n","# Instanciar o modelo\n","model = SimpleMLP().to(device)\n","print(model)\n","\n","# Definir a função de perda\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(model.parameters(), lr=0.001)\n","\n","\n","\n","model_perform={}\n","#treina o modelo com 30 epocas\n","model_perform['train_losses'], model_perform['validation_losses'] = train(model, trainloader, testloader, criterion, optimizer, epochs=50)\n","model_perform['accuracy'] = test(model, testloader)\n","results_mlp['sgd'] = model_perform\n","torch.save(model.state_dict(),'sgd_mlp_cifar10')\n","\n","\n","# #SGD\n","\n","# # Instanciar o modelo\n","# model = SimpleCNN().to(device)\n","# print(model)\n","\n","# # Definir a função de perda\n","# criterion = nn.CrossEntropyLoss()\n","# optimizer = optim.SGD(model.parameters(), lr=0.001)\n","\n","\n","\n","# model_perform={}\n","# #treina o modelo com 30 epocas\n","# model_perform['train_losses'], model_perform['validation_losses'] = train(model, trainloader, testloader, criterion, optimizer, epochs=50)\n","# model_perform['accuracy'] = test(model, testloader)\n","# results['sgd'] = model_perform\n","# torch.save(model.state_dict(),'sgd_cnn_cifar10')"],"metadata":{"id":"I0oK_vwmlxIM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train_hess(model, trainloader, testloader, criterion, optimizer, epochs=10):\n","    train_losses = []\n","    val_losses = []\n","\n","    for epoch in range(epochs):\n","        #training\n","        model.train()\n","        train_loss = 0.0\n","        for inputs, labels in trainloader:\n","            inputs, labels = inputs.to(device), labels.to(device)\n","\n","\n","            outputs = model(inputs)\n","            loss = criterion(outputs, labels)\n","\n","            optimizer.zero_grad()\n","            loss.backward(create_graph=True)\n","            optimizer.step()\n","\n","\n","            train_loss += loss.item()*inputs.size(0)\n","        train_loss = train_loss/len(trainloader.dataset)\n","        train_losses.append(train_loss)\n","\n","        #validation\n","        model.eval()\n","        val_loss = 0.0\n","        correct = 0\n","        total = 0\n","        with torch.no_grad():\n","            for inputs, labels in testloader:\n","                inputs, labels = inputs.to(device), labels.to(device)\n","\n","                # Forward pass\n","                outputs = model(inputs)\n","                loss = criterion(outputs, labels)\n","\n","                val_loss += loss.item() * inputs.size(0)\n","\n","                # Calculate accuracy\n","                _, predicted = torch.max(outputs.data, 1)\n","                total += labels.size(0)\n","                correct += (predicted == labels).sum().item()\n","\n","        val_loss = val_loss / len(testloader.dataset)\n","        val_losses.append(val_loss)\n","        print('Epoch [{}/{}], Train Loss: {:.4f}, Val Loss: {:.4f}, Val Acc: {:.2f}%'\n","              .format(epoch+1, epochs, train_loss, val_loss, 100 * correct / total))\n","\n","\n","\n","\n","\n","    print(\"Finished Training/Validation\")\n","    return train_losses.copy(), val_losses.copy()\n","\n","\n","\n","#ADAHESSIAN\n","\n","# Instanciar o modelo\n","model = SimpleMLP().to(device)\n","print(model)\n","\n","# Definir a função de perda\n","criterion = nn.CrossEntropyLoss()\n","optimizer = ada_optim.Adahessian(model.parameters(), lr = 0.001)\n","\n","\n","\n","model_perform={}\n","#treina o modelo com 30 epocas\n","model_perform['train_losses'], model_perform['validation_losses'] = train_hess(model, trainloader, testloader, criterion, optimizer, epochs=50)\n","model_perform['accuracy'] = test(model, testloader)\n","results_mlp['Adahessian'] = model_perform\n","torch.save(model.state_dict(),'adahessian_mlp_cifar10')"],"metadata":{"id":"3v18JfWMmBpu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import json\n","with open('results_mlp.json', 'w') as f:\n","    json.dump(results_mlp, f)\n","results_mlp"],"metadata":{"id":"C0Ds_QUYnPut"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[{"file_id":"1QOT7u9lQkqJOkqkwA7PPjw38G4VAmpBr","timestamp":1714263008908}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}